Отчёт за 22.10 - 06.11

1. Нашел проблему с None значениями в производных:
    - неправильное транспонирование
    - неправильное применение GradientType для дифф-я сложной ф-ии
    
    Исправлено ( код переписал )

2. Исходных данных оказалось недостаточно для обучения -> 
-> использовано семплирование ( исскуственная генерация ) с помощью latin hypercube из pyDOE

3. Сделана нейронная сеть с помощью стратегии эксп-го уменьшения скорости обучения и оптимизатора Адам

4. Рез-ты получились не очень -> попробовал добавить вес к каждой ф-ии ошибки ( по ур-ю  и {г.у. + н.у.} ), по которым моделька обучается ->
-> получилось еще хуже ^_^ -> может, криво сделал, пока не стал это использовать

5. Построены графики сравнения предикта и исходных значений ( см. Data_Model_View_notebook.ipynb в конце либо в /pictures/temp ) ->
-> Пока не оч, особенно графики в начальные моменты + ф-я не падает до нуля -> буду играться со слоями, шагом обучения и ф-ей relu на последнем слое

