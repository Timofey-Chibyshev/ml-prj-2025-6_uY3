import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from torchvision import datasets, transforms, models
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score
import matplotlib.pyplot as plt
import numpy as np
from pathlib import Path
import argparse
from tqdm import tqdm

def build_model(model_name, num_classes):
    """–°—Ç—Ä–æ–∏—Ç –º–æ–¥–µ–ª—å —Å —É–∫–∞–∑–∞–Ω–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π"""
    if model_name == "resnet50":
        model = models.resnet50(weights=None)
        in_features = model.fc.in_features
        model.fc = nn.Linear(in_features, num_classes)
    elif model_name == "efficientnet_b0":
        model = models.efficientnet_b0(weights=None)
        in_features = model.classifier[1].in_features
        model.classifier[1] = nn.Linear(in_features, num_classes)
    elif model_name == "mobilenet_v3_small":
        model = models.mobilenet_v3_small(weights=None)
        in_features = model.classifier[3].in_features
        model.classifier[3] = nn.Linear(in_features, num_classes)
    else:
        raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –º–æ–¥–µ–ª—å: {model_name}")
    return model

def load_test_data(data_dir, batch_size=16):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ"""
    test_transforms = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                           std=[0.229, 0.224, 0.225])
    ])
    
    test_ds = datasets.ImageFolder(data_dir / "test", transform=test_transforms)
    test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False)
    
    return test_loader, test_ds.classes, test_ds.class_to_idx

def test_model(model_path, model_name, num_classes, data_dir, output_dir="test_results"):
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –º–æ–¥–µ–ª—å –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏"""
    
    output_path = Path(output_dir)
    output_path.mkdir(exist_ok=True)
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"üöÄ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")
    
    print("üìÅ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
    test_loader, class_names, class_to_idx = load_test_data(Path(data_dir))
    print(f"üîπ –ö–ª–∞—Å—Å—ã: {class_names}")
    print(f"üîπ –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∫–ª–∞—Å—Å–æ–≤: {class_to_idx}")
    
    if num_classes != len(class_names):
        print(f"‚ö†Ô∏è –í–Ω–∏–º–∞–Ω–∏–µ: —É–∫–∞–∑–∞–Ω–æ {num_classes} –∫–ª–∞—Å—Å–æ–≤, –Ω–æ –Ω–∞–π–¥–µ–Ω–æ {len(class_names)} –∫–ª–∞—Å—Å–æ–≤ –≤ –¥–∞–Ω–Ω—ã—Ö")
        print(f"üîπ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —á–∏—Å–ª–æ –∫–ª–∞—Å—Å–æ–≤ –∏–∑ –¥–∞–Ω–Ω—ã—Ö: {len(class_names)}")
        num_classes = len(class_names)
    
    print(f"üß† –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏: {model_name}")
    model = build_model(model_name, num_classes).to(device)
    
    print(f"üì• –ó–∞–≥—Ä—É–∑–∫–∞ –≤–µ—Å–æ–≤ –∏–∑: {model_path}")
    try:
        checkpoint = torch.load(model_path, map_location=device)
        
        if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:
            model.load_state_dict(checkpoint['model_state_dict'])
            print("‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω checkpoint —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π")
        else:
            model.load_state_dict(checkpoint)
            print("‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω state_dict –º–æ–¥–µ–ª–∏")
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –º–æ–¥–µ–ª–∏: {e}")
        return None
    
    print("üß™ –ù–∞—á–∞–ª–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è...")
    model.eval()
    all_preds, all_labels, all_probs = [], [], []
    
    with torch.no_grad():
        for images, labels in tqdm(test_loader, desc="–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ"):
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            probs = torch.softmax(outputs, dim=1)
            _, preds = torch.max(outputs, 1)
            
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
            all_probs.extend(probs.cpu().numpy())
    
    print("\nüìä –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫...")
    accuracy = accuracy_score(all_labels, all_preds)
    precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)
    recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)
    f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)
    kappa = cohen_kappa_score(all_labels, all_preds)
    
    print("\n" + "="*50)
    print("üìà –†–ï–ó–£–õ–¨–¢–ê–¢–´ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø")
    print("="*50)
    print(f"–ú–æ–¥–µ–ª—å: {model_name}")
    print(f"–§–∞–π–ª –º–æ–¥–µ–ª–∏: {model_path}")
    print(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤: {num_classes}")
    print(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ—Å—Ç–æ–≤—ã—Ö –æ–±—Ä–∞–∑—Ü–æ–≤: {len(all_labels)}")
    print("\nüìä –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏:")
    print(f"Accuracy: {accuracy:.4f}")
    print(f"Precision: {precision:.4f}")
    print(f"Recall: {recall:.4f}")
    print(f"F1-Score: {f1:.4f}")
    print(f"Cohen's Kappa: {kappa:.4f}")
    
    print("\nüìã –î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç –ø–æ –∫–ª–∞—Å—Å–∞–º:")
    print(classification_report(all_labels, all_preds, target_names=class_names, zero_division=0))
    
    cm = confusion_matrix(all_labels, all_preds)
    plt.figure(figsize=(10, 8))
    im = plt.imshow(cm, cmap="Blues")
    
    for i in range(len(class_names)):
        for j in range(len(class_names)):
            plt.text(j, i, cm[i, j], 
                    ha="center", va="center", 
                    color="white" if cm[i, j] > cm.max()/2 else "black",
                    fontsize=10)
    
    plt.colorbar(im)
    plt.xticks(np.arange(len(class_names)), class_names, rotation=45, ha="right")
    plt.yticks(np.arange(len(class_names)), class_names)
    plt.xlabel("–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –º–µ—Ç–∫–∏")
    plt.ylabel("–ò—Å—Ç–∏–Ω–Ω—ã–µ –º–µ—Ç–∫–∏")
    plt.title(f"Confusion Matrix\nAccuracy: {accuracy:.4f}")
    plt.tight_layout()
    
    cm_path = output_path / f"confusion_matrix_{model_name}.png"
    plt.savefig(cm_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"‚úÖ Confusion matrix —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {cm_path}")
    
    class_accuracy = cm.diagonal() / cm.sum(axis=1)
    plt.figure(figsize=(10, 6))
    bars = plt.bar(range(len(class_names)), class_accuracy)
    plt.xticks(range(len(class_names)), class_names, rotation=45, ha="right")
    plt.ylabel("Accuracy")
    plt.title("Accuracy –ø–æ –∫–ª–∞—Å—Å–∞–º")
    plt.ylim(0, 1)
    
    for bar, acc in zip(bars, class_accuracy):
        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, 
                f'{acc:.3f}', ha='center', va='bottom')
    
    plt.tight_layout()
    class_acc_path = output_path / f"class_accuracy_{model_name}.png"
    plt.savefig(class_acc_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"‚úÖ –ì—Ä–∞—Ñ–∏–∫ accuracy –ø–æ –∫–ª–∞—Å—Å–∞–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {class_acc_path}")
    
    metrics_file = output_path / f"metrics_{model_name}.txt"
    with open(metrics_file, 'w', encoding='utf-8') as f:
        f.write(f"–ú–æ–¥–µ–ª—å: {model_name}\n")
        f.write(f"–§–∞–π–ª –º–æ–¥–µ–ª–∏: {model_path}\n")
        f.write(f"–ö–ª–∞—Å—Å—ã: {class_names}\n")
        f.write(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ—Å—Ç–æ–≤—ã—Ö –æ–±—Ä–∞–∑—Ü–æ–≤: {len(all_labels)}\n\n")
        f.write("–ú–µ—Ç—Ä–∏–∫–∏:\n")
        f.write(f"Accuracy: {accuracy:.4f}\n")
        f.write(f"Precision: {precision:.4f}\n")
        f.write(f"Recall: {recall:.4f}\n")
        f.write(f"F1-Score: {f1:.4f}\n")
        f.write(f"Cohen's Kappa: {kappa:.4f}\n\n")
        f.write("Classification Report:\n")
        f.write(classification_report(all_labels, all_preds, target_names=class_names, zero_division=0))
    
    print(f"üíæ –ü–æ–ª–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {metrics_file}")
    
    return {
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1_score': f1,
        'kappa': kappa,
        'predictions': all_preds,
        'labels': all_labels,
        'probabilities': all_probs,
        'class_names': class_names
    }

def main():
    parser = argparse.ArgumentParser(description="–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏")
    parser.add_argument("--model_path", type=str, required=True, help="–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª—å—é")
    parser.add_argument("--model_name", type=str, required=True, 
                       choices=["resnet50", "efficientnet_b0", "mobilenet_v3_small"],
                       help="–ù–∞–∑–≤–∞–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –º–æ–¥–µ–ª–∏")
    parser.add_argument("--num_classes", type=int, required=True, help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤")
    parser.add_argument("--data_dir", type=str, default="data_split", help="–ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å –¥–∞–Ω–Ω—ã–º–∏")
    parser.add_argument("--output_dir", type=str, default="test_results", help="–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
    
    args = parser.parse_args()
    
    print("üß™ –ó–ê–ü–£–°–ö –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø –ú–û–î–ï–õ–ò")
    print("="*50)
    
    results = test_model(
        model_path=args.model_path,
        model_name=args.model_name,
        num_classes=args.num_classes,
        data_dir=args.data_dir,
        output_dir=args.output_dir
    )
    
    if results is not None:
        print("\nüéâ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ!")
    else:
        print("\n‚ùå –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —Å –æ—à–∏–±–∫–∞–º–∏!")

if __name__ == "__main__":
    main()
    