# Отчёт за 8 неделю проекта "Классификация текста по настроению"

---
## Цели недели
- Обучить и сравнить три модели машинного обучения для анализа тональности текста.
- Провести интерпретацию результатов.
- Сделать выводы о качестве моделей.
---

## Выполненные задачи

### 1. Обученные модели
В рамках экспериментов обучены три модели:
1. **Логистическая регрессия (Logistic Regression)** — линейный классификатор.
2. **Линейный SVM (LinearSVC)** — метод опорных векторов с линейным ядром и калибровкой вероятностей.
3. **Наивный Байес (MultinomialNB)** — вероятностная модель, использующая частоты слов для оценки классов.

---

### 2. Использованные метрики
Для оценки качества моделей рассчитаны:
- Accuracy (точность классификации)
- Precision (точность положительных предсказаний)
- Recall (полнота)
- F1-score (гармоническое среднее между precision и recall)

---

### 3. Результаты сравнения моделей

| Модель | Accuracy | Precision (взвеш.) | Recall (взвеш.) | F1-score (взвеш.) |
|---------|-----------|--------------------|-----------------|-------------------|
| Logistic Regression | 0.793 | 0.79 | 0.79 | 0.79 |
| LinearSVC | 0.806 | 0.81 | 0.80 | **0.80** |
| MultinomialNB | 0.785 | 0.78 | 0.78 | 0.78 |

---

### 4. Примеры визуализации

**Матрица ошибок (Logistic Regression):**
```
[[133626  40284]
 [ 31955 144133]]
```

**Кривые ROC и PR** показывают, что LinearSVC демонстрирует наилучший баланс между полнотой и точностью, а Logistic Regression показывает устойчивое качество на уровне 0.79.

---

### 5. Интерпретация признаков

**Положительные слова:**
> love, good, great, fantastic, amazing, wonderful, happy, enjoy, awesome, nice

**Отрицательные слова:**
> bad, hate, terrible, worst, awful, boring, stupid, disappointed, ugly, sad

Эти слова логично отражают оценочные категории и подтверждают адекватность работы моделей.

---

## Выводы по 8 неделе

- Обучены и протестированы три ключевые модели.
- LinearSVC показала наилучшее качество (F1 ≈ 0.80).
- Логистическая регрессия демонстрирует стабильный и интерпретируемый результат (F1 ≈ 0.79).
- Модель Наивного Байеса остаётся быстрым базовым ориентиром (F1 ≈ 0.78).
- Все модели подтвердили корректность предобработки и TF-IDF векторизации.

---

## План на 9 неделю

- Добавить нейросетевые подходы (LSTM, BERT).
- Исследовать интерпретацию моделей через SHAP или LIME.
- Подготовить визуальные материалы (графики, примеры текстов, отчёты).

---
